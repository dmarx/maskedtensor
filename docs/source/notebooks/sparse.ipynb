{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/maskedtensor/blob/main/docs/source/notebooks/sparse.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sparsity in PyTorch](https://pytorch.org/docs/stable/sparse.html) is a quickly growing area that has found a lot of support and demand due to its efficiency in both memory and compute. This tutorial is meant to be used in conjunction with the the PyTorch link above, as the sparse tensors are ultimately the building blocks for MaskedTensors (just as regular `torch.Tensor`s are as well).\n",
    "\n",
    "Sparse storage formats are particularly powerful in scenarios where the majority of elements are equal to zero. There are a number of different [sparse storage formats](https://en.wikipedia.org/wiki/Sparse_matrix) that can be leveraged with various tradeoffs and degrees of adoption.\n",
    "\n",
    "Noting PyTorch's terminology of \"specified\" and \"unspecified\" elements (e.g. the elements that are actually stored vs. not), the parallel to MaskedTensor's usage is clear. However, by allowing a mask as well, MaskedTensors are even more generalizable, as we'l show through the tutorial - e.g. when the mask all `True`, most operations will result in the same result, but when the mask indicates unspecified values, then values in the sparse tensor will be masked out.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:** Currently, only the COO sparse storage format is supported in MaskedTensor ([CSR is being developed](https://github.com/pytorch/maskedtensor/pull/65)). If you have another format that you would like supported, please file an issue!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `input` and `mask` must have the same storage format, whether that's `torch.strided`, `torch.sparse_coo`, or `torch.sparse_csr`.\n",
    "\n",
    "2. `input` and `mask` must have the same size, indicated by `t.size()`\n",
    "\n",
    "3. `input` and `mask` - only for sparse formats - can have a different number of elements (`tensor.nnz()`) **at creation**, the indices of `mask` must then be a subset of the indices from `input`. In this case, `input` will assume the shape of mask using the function `input.sparse_mask(mask)`; in other words, any of the elements in `input` that are not `True` in `mask` will be thrown away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse COO Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from maskedtensor import masked_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In according with Principle #1, a MaskedTensor is created by passing in two sparse tensors, which can be initialized with any of the constructors, e.g. `torch.sparse_coo_tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values:\n",
      " tensor([[0, 0, 3],\n",
      "        [4, 0, 5]])\n",
      "mask:\n",
      " tensor([[False, False,  True],\n",
      "        [False, False,  True]])\n",
      "mt:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 3],\n",
      "    [      --,       --, 5]\n",
      "  ]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "i = [[0, 1, 1],\n",
    "     [2, 0, 2]]\n",
    "v =  [3, 4, 5]\n",
    "m = torch.tensor([True, False, True])\n",
    "\n",
    "values = torch.sparse_coo_tensor(i, v, (2, 3))\n",
    "mask = torch.sparse_coo_tensor(i, m, (2, 3))\n",
    "\n",
    "mt = masked_tensor(values, mask)  \n",
    "\n",
    "print(\"values:\\n\", values.to_dense())\n",
    "print(\"mask:\\n\", mask.to_dense())\n",
    "print(\"mt:\\n\", mt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A word of warning: when using a function like `.to_sparse_coo()`, if the user does not specify the indices like in the above example, then 0 values will be default \"unspecified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values:\n",
      " tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 0, 2]]),\n",
      "       values=tensor([3, 4, 5]),\n",
      "       size=(2, 3), nnz=3, layout=torch.sparse_coo)\n",
      "mask:\n",
      " tensor(indices=tensor([[0, 1],\n",
      "                       [2, 2]]),\n",
      "       values=tensor([True, True]),\n",
      "       size=(2, 3), nnz=2, layout=torch.sparse_coo)\n",
      "mt2:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 3],\n",
      "    [      --,       --, 5]\n",
      "  ]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "i = [[0, 1, 1],\n",
    "     [2, 0, 2]]\n",
    "v =  [3, 4, 5]\n",
    "m = torch.tensor(\n",
    "     [[False, False, True],\n",
    "      [False, False, True]]\n",
    ")\n",
    "\n",
    "values = torch.sparse_coo_tensor(i, v, (2, 3))\n",
    "mask = m.to_sparse_coo()\n",
    "mt2 = masked_tensor(values, mask)\n",
    "\n",
    "print(\"values:\\n\", values)\n",
    "print(\"mask:\\n\", mask)\n",
    "print(\"mt2:\\n\", mt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principle 3: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `mt` and `mt2` will have the same value in the vast majority of operations, but it's worth noting that in line with Principle #3, under the hood, the data looks slightly different; `mt` has the 4 value masked out and `mt2` is completely without it. In other words, their underlying data still has different shapes, so `mt + mt2` is invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt.masked_data:\n",
      " tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 0, 2]]),\n",
      "       values=tensor([3, 4, 5]),\n",
      "       size=(2, 3), nnz=3, layout=torch.sparse_coo)\n",
      "mt2.masked_data:\n",
      " tensor(indices=tensor([[0, 1],\n",
      "                       [2, 2]]),\n",
      "       values=tensor([3, 5]),\n",
      "       size=(2, 3), nnz=2, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "print(\"mt.masked_data:\\n\", mt.masked_data)\n",
    "print(\"mt2.masked_data:\\n\", mt2.masked_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All unary operations are supported; for a list of operations, please refer to [here](https://pytorch.org/maskedtensor/main/unary.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_tensor(\n",
       "  [\n",
       "    [      --,       --,   0.1411],\n",
       "    [      --,       --,  -0.9589]\n",
       "  ]\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the usual case of masked binary operations, the input masks from the two masked tensors must match. For a list of operations, please refer [here](https://pytorch.org/maskedtensor/main/binary.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [[0, 1, 1],\n",
    "     [2, 0, 2]]\n",
    "v1 = [3, 4, 5]\n",
    "v2 = [20, 30, 40]\n",
    "m = torch.tensor([True, False, True])\n",
    "\n",
    "s1 = torch.sparse_coo_tensor(i, v1, (2, 3))\n",
    "s2 = torch.sparse_coo_tensor(i, v2, (2, 3))\n",
    "mask = torch.sparse_coo_tensor(i, m, (2, 3))\n",
    "\n",
    "mt1 = masked_tensor(s1, mask)\n",
    "mt2 = masked_tensor(s2, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt1:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 3],\n",
      "    [      --,       --, 5]\n",
      "  ]\n",
      ")\n",
      "mt2:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 20],\n",
      "    [      --,       --, 40]\n",
      "  ]\n",
      ")\n",
      "torch.div(mt2, mt1):\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --,   6.6667],\n",
      "    [      --,       --,   8.0000]\n",
      "  ]\n",
      ")\n",
      "torch.mul(mt1, mt2):\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 60],\n",
      "    [      --,       --, 200]\n",
      "  ]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"mt1:\\n\", mt1)\n",
    "print(\"mt2:\\n\", mt2)\n",
    "print(\"torch.div(mt2, mt1):\\n\", torch.div(mt2, mt1))\n",
    "print(\"torch.mul(mt1, mt2):\\n\", torch.mul(mt1, mt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, only reductions across all dimensions are supported and not a particular dimension (e.g. `mt.sum()` is supported but not `mt.sum(dim=1)`). For a list of supported reductions, please refer [here](https://pytorch.org/maskedtensor/main/reductions.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 3],\n",
      "    [      --,       --, 5]\n",
      "  ]\n",
      ")\n",
      "mt.sum():\n",
      " masked_tensor(8, True)\n",
      "mt.amin():\n",
      " masked_tensor(3, True)\n"
     ]
    }
   ],
   "source": [
    "print(\"mt:\\n\", mt)\n",
    "print(\"mt.sum():\\n\", mt.sum())\n",
    "print(\"mt.amin():\\n\", mt.amin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaskedTensor methods and sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_dense()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_tensor(\n",
       "  [\n",
       "    [      --,       --, 3],\n",
       "    [      --,       --, 5]\n",
       "  ]\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_sparse_coo()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [[3, 0, 0],\n",
    "     [0, 4, 5]]\n",
    "m = [[True, False, False],\n",
    "     [False, True, True]]\n",
    "mt = masked_tensor(torch.tensor(v), torch.tensor(m))\n",
    "\n",
    "mt_sparse = mt.to_sparse_coo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_sparse` / `is_sparse_coo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt.is_sparse:  False\n",
      "mt_sparse.is_sparse:  True\n",
      "mt.is_sparse_coo:  False\n",
      "mt_sparse.is_sparse_coo:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"mt.is_sparse: \", mt.is_sparse())\n",
    "print(\"mt_sparse.is_sparse: \", mt_sparse.is_sparse())\n",
    "\n",
    "print(\"mt.is_sparse_coo: \", mt.is_sparse_coo())\n",
    "print(\"mt_sparse.is_sparse_coo: \", mt_sparse.is_sparse_coo())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0a07e0fa82e52b776976e55e335decf2d0ac48acfa03bb0e56e7f3ca52a96d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
